{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deep NLP - Word Embeddings\n",
    "\n",
    "#### Agenda today\n",
    "- Review foundations of NLP: Bag of words vs tf-df\n",
    "- Representing contexts & preserving meaning of words: Continous bag of words\n",
    "- Implementing word2vec\n",
    "\n",
    "Think back to NLP as we've understood it so far.\n",
    "\n",
    "If we've had some luck with NLP modeling, likely with a NaiveBayes algorithm, we were able to illustrate some correlations between words and some other feature of interest.\n",
    "\n",
    "But to whatever extent that our models were able to make connections and pick up on correlations, they did this *without any understanding of the **meaning** of the words in question*.\n",
    "\n",
    "Let's think for a minute about words and objective meanings!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can make sense of meaning for computational purposes by thinking about meaning in terms of similarity, i.e. thinking about meaning *holistically*.\n",
    "\n",
    "Q. Is there any precedent for this way of thinking about meaning? <br/>\n",
    "A. [Yes](https://plato.stanford.edu/entries/meaning-holism/#ArgForMeaHol)\n",
    "\n",
    "So what will this look like for us?\n",
    "\n",
    "*Remember cosine similarity?*\n",
    "\n",
    "$\\rightarrow$We'll have much the same idea here: Associate each word with values along particular dimensions in a multi-dimensional space. If we had a dimension for *softness*, for example, then pillows and marshmallows would score higher on it than rocks and bricks."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Continous Bag of Words (CBOW)\n",
    "The goal of continous bag of words is to predict _the probability_ of a word given some context. A context may be a single word or a vector of words. Below is the architecture of the model. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='cbow.jpeg' width = 400>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### CBOW step by step \n",
    "- The input layer and the target, both are one- hot encoded of size [1 X V]\n",
    "\n",
    "- There are two sets of weights. one is between the input and the hidden layer and second between hidden and output layer.\n",
    "\n",
    "- Input-Hidden layer matrix size =[V X N] , hidden-Output layer matrix  size =[N X V] where N represents the number of neurons in the hidden layers. \n",
    "\n",
    "- The activation function in the hidden layer is linear! \n",
    "\n",
    "- The input is multiplied by the input-hidden weights and called hidden activation. It's the corresponding row in the input matrix, very similar to how sum of weights are calculated in MLP.\n",
    "\n",
    "- The hidden input gets multiplied by hidden- output weights and output is calculated.\n",
    "\n",
    "- Error between output and target is calculated and backpropagation is used to adjust the weight initialized before. \n",
    "\n",
    "- The weight  between the hidden layer and the output layer is taken as the __word vector representation of the word__ -> hence, word to vec!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Implementing word2vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reading in the data\n",
    "\n",
    "import json\n",
    "\n",
    "with open('JEOPARDY_QUESTIONS1.json') as f:\n",
    "    data = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "216930"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'category': 'HISTORY',\n",
       " 'air_date': '2004-12-31',\n",
       " 'question': \"'For the last 8 years of his life, Galileo was under house arrest for espousing this man's theory'\",\n",
       " 'value': '$200',\n",
       " 'answer': 'Copernicus',\n",
       " 'round': 'Jeopardy!',\n",
       " 'show_number': '4680'}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's look at the first element in our list\n",
    "\n",
    "data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "98"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# How many words do we have?\n",
    "\n",
    "len(data[0]['question'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"'For\",\n",
       " 'the',\n",
       " 'last',\n",
       " '8',\n",
       " 'years',\n",
       " 'of',\n",
       " 'his',\n",
       " 'life,',\n",
       " 'Galileo',\n",
       " 'was',\n",
       " 'under',\n",
       " 'house',\n",
       " 'arrest',\n",
       " 'for',\n",
       " 'espousing',\n",
       " 'this',\n",
       " \"man's\",\n",
       " \"theory'\"]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's try that again!\n",
    "\n",
    "\n",
    "\n",
    "data[0]['question'].split(' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "18"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data[0]['question'].split(' '))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3169994"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "length = 0\n",
    "for clue in data:\n",
    "    length += len(clue['question'].split(' '))\n",
    "length"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using Word2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Word2Vec requires that our text have the form of a list\n",
    "# of 'sentences', where each sentence is itself a list of\n",
    "# words. How can we put our _Jeopardy!_ clues in that shape?\n",
    "\n",
    "import string\n",
    "text = []\n",
    "\n",
    "for clue in data:\n",
    "    sentence = clue['question'].translate(str.maketrans('', '',\n",
    "                                                        string.punctuation)).split(' ')\n",
    "    \n",
    "    new_sent = []\n",
    "    for word in sentence:\n",
    "        new_sent.append(word.lower())\n",
    "    \n",
    "    text.append(new_sent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['for',\n",
       " 'the',\n",
       " 'last',\n",
       " '8',\n",
       " 'years',\n",
       " 'of',\n",
       " 'his',\n",
       " 'life',\n",
       " 'galileo',\n",
       " 'was',\n",
       " 'under',\n",
       " 'house',\n",
       " 'arrest',\n",
       " 'for',\n",
       " 'espousing',\n",
       " 'this',\n",
       " 'mans',\n",
       " 'theory']"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's check the new structure of our first clue\n",
    "\n",
    "text[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "King + Woman - Man = Queen\n",
    "\n",
    "Brother + Woman - Man = Sister"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Constructing the model is simply a matter of\n",
    "# instantiating a Word2Vec object.\n",
    "\n",
    "model = gensim.models.Word2Vec(text, sg=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(11335282, 15849970)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# To train, call 'train()'!\n",
    "\n",
    "model.train(text, total_examples=model.corpus_count, epochs=model.epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3169994"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.corpus_total_words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## model.wv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<gensim.models.keyedvectors.Word2VecKeyedVectors at 0x1a42cb02e8>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The '.wv' attribute stores the word vectors\n",
    "\n",
    "model.wv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.02013678, -0.768867  , -0.3995168 ,  0.20007966,  0.07782069,\n",
       "        0.3070786 , -0.02616971,  0.22320455, -0.19875549, -0.48531622,\n",
       "       -0.3757766 , -0.05396411, -0.04683578, -0.11336355, -0.22662023,\n",
       "        0.01906323,  0.021305  ,  0.05067752,  0.12077358,  0.11734386,\n",
       "       -0.516456  , -0.05390289, -0.00173848,  0.3537908 ,  0.1281792 ,\n",
       "        0.64577883,  0.23364232,  0.40055946, -0.22854975,  0.20258924,\n",
       "       -0.05578034, -0.10420907, -0.42711267,  0.28573084, -0.17423692,\n",
       "       -0.41932258,  0.06479436,  0.04241097, -0.19720377, -0.02992231,\n",
       "       -0.20466733,  0.30786785,  0.17101948,  0.17466737,  0.4910097 ,\n",
       "       -0.4866816 , -0.12191375, -0.25491777, -0.25815502, -0.18216774,\n",
       "       -0.11897507,  0.3471193 , -0.71689504, -0.03110847, -0.25038064,\n",
       "       -0.3100907 ,  0.4050753 ,  0.24704766,  0.16912584,  0.32673478,\n",
       "       -0.3095468 ,  0.41637126, -0.05078639, -0.28241867, -0.4771867 ,\n",
       "       -0.11264411, -0.09655994, -0.00761371, -0.01329694, -0.37042597,\n",
       "       -0.5170597 ,  0.2916241 ,  0.43721086,  0.02888383, -0.28883433,\n",
       "        0.3714908 ,  0.09191638,  0.26765546, -0.06118785, -0.05984275,\n",
       "       -0.24512957, -0.02917294, -0.08107141, -0.13322699,  0.02569427,\n",
       "       -0.3311703 , -0.25485846,  0.20457475, -0.36314213, -0.21679628,\n",
       "        0.420247  ,  0.4637942 , -0.3161796 , -0.00584209,  0.21209772,\n",
       "       -0.42580587,  0.21596745, -0.21152313, -0.05727901, -0.539514  ],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv['child']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### model.wv methods\n",
    "#### 'most_similar()' and 'similarity()'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('drip', 0.847236156463623),\n",
       " ('pottery', 0.8100799322128296),\n",
       " ('ceramic', 0.7932129502296448),\n",
       " ('decorative', 0.7931036353111267),\n",
       " ('canvas', 0.7903770208358765),\n",
       " ('fastener', 0.7888020277023315),\n",
       " ('linen', 0.7869349718093872),\n",
       " ('trapeze', 0.7865070104598999),\n",
       " ('wrap', 0.78385329246521),\n",
       " ('artwork', 0.7797967195510864)]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv.most_similar('furniture')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.77938473"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv.similarity('furniture', 'jewelry')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('parrot', 0.873432457447052),\n",
       " ('rodent', 0.8573928475379944),\n",
       " ('carnivore', 0.8493756651878357),\n",
       " ('wading', 0.8472229838371277),\n",
       " ('reptile', 0.843704342842102),\n",
       " ('marsupial', 0.8394194841384888),\n",
       " ('lizard', 0.838648796081543),\n",
       " ('shorttailed', 0.8353908061981201),\n",
       " ('predatory', 0.8343661427497864),\n",
       " ('arachnid', 0.8338077664375305)]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv.most_similar(positive=['cat', 'animal', 'pet', 'mammal'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('mammal', 0.35181742906570435),\n",
       " ('species', 0.34889715909957886),\n",
       " ('lizard', 0.3367321491241455),\n",
       " ('creature', 0.3365228772163391),\n",
       " ('insect', 0.3316500186920166),\n",
       " ('rodent', 0.3236585259437561),\n",
       " ('animals', 0.31926828622817993),\n",
       " ('marsupial', 0.31866103410720825),\n",
       " ('extinct', 0.30677351355552673),\n",
       " ('birds', 0.304746150970459)]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv.most_similar(positive=['cat', 'animal'], negative='pet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('empress', 0.49203425645828247),\n",
       " ('throne', 0.4811129570007324),\n",
       " ('queen', 0.480634868144989)]"
      ]
     },
     "execution_count": 191,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv.most_similar(positive=['king', 'woman'], negative='man', topn=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('pageant', 0.5714678764343262),\n",
       " ('fargo', 0.5668860673904419),\n",
       " ('minneapolis', 0.5316091775894165),\n",
       " ('90210', 0.5216965079307556),\n",
       " ('summer', 0.5198173522949219),\n",
       " ('bronx', 0.5194722414016724),\n",
       " ('edina', 0.5112684965133667),\n",
       " ('tonight', 0.5014094114303589),\n",
       " ('yesterday', 0.4972144365310669),\n",
       " ('bway', 0.4931708872318268)]"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv.most_similar(positive='usa')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('hawaii', 0.7062503099441528),\n",
       " ('switzerland', 0.7037385702133179),\n",
       " ('territory', 0.7032467126846313),\n",
       " ('alaska', 0.6920301914215088),\n",
       " ('peru', 0.6817297339439392),\n",
       " ('colombia', 0.6571628451347351),\n",
       " ('pakistan', 0.6542963981628418),\n",
       " ('morocco', 0.644716739654541),\n",
       " ('japan', 0.6415838003158569),\n",
       " ('statehood', 0.6406919360160828)]"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv.most_similar('canada')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('hemingway', 0.6982564330101013),\n",
       " ('tennyson', 0.6815193295478821),\n",
       " ('hamlet', 0.6687659621238708),\n",
       " ('dickens', 0.6686815023422241),\n",
       " ('poe', 0.6508814692497253),\n",
       " ('shakespeares', 0.6488662958145142),\n",
       " ('macbeth', 0.6414898633956909),\n",
       " ('shelley', 0.6403170824050903),\n",
       " ('tolstoy', 0.6312527060508728),\n",
       " ('eliot', 0.6235682964324951)]"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv.most_similar('shakespeare')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('kinnear', 0.851963460445404),\n",
       " ('hatcher', 0.8268362283706665),\n",
       " ('reese', 0.8254306316375732),\n",
       " ('2004br', 0.8243862986564636),\n",
       " ('det', 0.8158860802650452),\n",
       " ('1989br', 0.8155031204223633),\n",
       " ('kiefer', 0.8080366253852844),\n",
       " ('randy', 0.8043558597564697),\n",
       " ('jake', 0.8002606630325317),\n",
       " ('bobby', 0.7988304495811462)]"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv.most_similar('greg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('quincy', 0.7526087760925293),\n",
       " ('madison', 0.7080703973770142),\n",
       " ('sen', 0.6974426507949829),\n",
       " ('dewey', 0.6706094741821289),\n",
       " ('hw', 0.6679573059082031),\n",
       " ('booker', 0.6666173934936523),\n",
       " ('josiah', 0.6663467884063721),\n",
       " ('marshall', 0.6623543500900269),\n",
       " ('rep', 0.6621801257133484),\n",
       " ('hoover', 0.6592093706130981)]"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv.most_similar('jefferson')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('lincoln', 0.6199996471405029),\n",
       " ('memorial', 0.6156197786331177),\n",
       " ('virginia', 0.5984926819801331),\n",
       " ('illinois', 0.5932536125183105),\n",
       " ('arlington', 0.5758087635040283),\n",
       " ('nebraska', 0.5739896297454834),\n",
       " ('missouri', 0.5725917816162109),\n",
       " ('texas', 0.5661277770996094),\n",
       " ('kansas', 0.565746545791626),\n",
       " ('montana', 0.5633023381233215)]"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv.most_similar('washington')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('february', 0.39004337787628174),\n",
       " ('remains', 0.38808560371398926),\n",
       " ('exile', 0.3841812312602997),\n",
       " ('dictator', 0.38287919759750366),\n",
       " ('1929', 0.379180908203125),\n",
       " ('1918', 0.37386244535446167),\n",
       " ('voyage', 0.37059006094932556),\n",
       " ('decade', 0.3700261414051056),\n",
       " ('russia', 0.3685533106327057),\n",
       " ('completed', 0.3664979338645935)]"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv.most_similar(positive=['president', 'germany'], negative='usa')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('exile', 0.3980652391910553),\n",
       " ('remains', 0.38099491596221924),\n",
       " ('voyage', 0.37491631507873535),\n",
       " ('shah', 0.36604753136634827),\n",
       " ('dictator', 0.35999220609664917),\n",
       " ('philippines', 0.3587689697742462),\n",
       " ('february', 0.3575618863105774),\n",
       " ('date', 0.3540005087852478),\n",
       " ('conquest', 0.35296034812927246),\n",
       " ('1793', 0.3519843816757202)]"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv.most_similar(positive=['president', 'france'], negative='usa')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 'doesnt_match()'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'frog'"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv.doesnt_match(['breakfast', 'lunch', 'frog', 'food'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'lunch'"
      ]
     },
     "execution_count": 194,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv.doesnt_match(['lunch', 'this'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'bush'"
      ]
     },
     "execution_count": 195,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv.doesnt_match(['tree', 'flower', 'bush', 'plant', 'toothbrush'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'toothbrush'"
      ]
     },
     "execution_count": 196,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv.doesnt_match(['tree', 'flower', 'plant', 'toothbrush'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 'closer_than()'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['prince', 'emperor', 'ruler']"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Which words are closer to 'king' than 'queen' is?\n",
    "\n",
    "model.wv.closer_than('king', 'queen')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 'distance()'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For this it will make more sense to\n",
    "# normalize our vectors.\n",
    "\n",
    "model.init_sims(replace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 199,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv.distance('king', 'king')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4097934365272522"
      ]
     },
     "execution_count": 206,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv.distance('joy', 'happiness')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 'evaluate_word_analogies()'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check out [this text file](https://raw.githubusercontent.com/nicholas-leonard/word2vec/master/questions-words.txt)!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [],
   "source": [
    "relatives = model.wv.evaluate_word_analogies('https://raw.githubusercontent.com/nicholas-leonard/word2vec/master/questions-words.txt')[1][4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "185"
      ]
     },
     "execution_count": 250,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(relatives['correct'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "235"
      ]
     },
     "execution_count": 251,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(relatives['incorrect'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('BOY', 'GIRL', 'BROTHER', 'SISTER'),\n",
       " ('BOY', 'GIRL', 'BROTHERS', 'SISTERS'),\n",
       " ('BOY', 'GIRL', 'DAD', 'MOM'),\n",
       " ('BOY', 'GIRL', 'FATHER', 'MOTHER'),\n",
       " ('BOY', 'GIRL', 'HE', 'SHE')]"
      ]
     },
     "execution_count": 253,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "relatives['correct'][:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('BOY', 'GIRL', 'GRANDFATHER', 'GRANDMOTHER'),\n",
       " ('BOY', 'GIRL', 'GRANDPA', 'GRANDMA'),\n",
       " ('BOY', 'GIRL', 'GRANDSON', 'GRANDDAUGHTER'),\n",
       " ('BOY', 'GIRL', 'GROOM', 'BRIDE'),\n",
       " ('BOY', 'GIRL', 'HUSBAND', 'WIFE')]"
      ]
     },
     "execution_count": 254,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "relatives['incorrect'][:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
